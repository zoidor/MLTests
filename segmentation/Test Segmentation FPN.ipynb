{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmentation of Cell Images using FPN and Keras\n",
    "\n",
    "We will implement a FPN (Feature Pyramid Networks) using Keras for image segmentation. \n",
    "Sources:\n",
    "- Original paper on FPN:  \"Feature Pyramid Networks for Object Detection\", Lin et al.\n",
    "- Inspiration from: https://github.com/cxhernandez/cellcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import os\n",
    "import pathlib\n",
    "import matplotlib\n",
    "import matplotlib.image\n",
    "import matplotlib.pyplot\n",
    "import sklearn.model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_dir = os.path.expanduser(\"~/ML_Segmentation_data/GroundTruth/\")\n",
    "images_dir = os.path.expanduser(\"~/ML_Segmentation_data/Images/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_file_extension = \".TIF\"\n",
    "image_names = os.listdir(ground_truth_dir)\n",
    "image_names = [x for x in image_names if x.endswith(img_file_extension)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of couples ground truth image - raw image\n",
    "image_paths = [(ground_truth_dir + im, images_dir + im) for im in image_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if all the couples have a corresponding file name and that the shape is the expected one\n",
    "expected_shape = (520, 696)\n",
    "cropped_size = (512, 688)\n",
    "\n",
    "def read_img_double(path, crop_size = None):\n",
    "    img = matplotlib.image.imread(path)\n",
    "    out = keras.backend.cast_to_floatx(img)\n",
    "    if(crop_size is None):\n",
    "        return out\n",
    "    return out[0 : crop_size[0], 0 : crop_size[1]]  \n",
    "    \n",
    "def check_file(path):\n",
    "    file_handle = pathlib.Path(path)\n",
    "    if not file_handle.is_file():\n",
    "        raise IOError(path + \" does not exist!\") \n",
    "    img = read_img_double(path)\n",
    "    if img.shape != expected_shape:\n",
    "        raise IOError(path + \" inconsistent shape! It has shape \" + str(img.shape))\n",
    "\n",
    "\n",
    "        \n",
    "def check_files_exist(couples):\n",
    "    for a,b in couples:\n",
    "        check_file(a)\n",
    "        check_file(b)\n",
    "    print(\"All files, both raws and ground truth exist and have correct dimensions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files, both raws and ground truth exist and have correct dimensions\n"
     ]
    }
   ],
   "source": [
    " check_files_exist(image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Divide train and test set\n",
    "train_imgs, test_imgs =  sklearn.model_selection.train_test_split(image_paths, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200\n",
      "1200\n",
      "960\n"
     ]
    }
   ],
   "source": [
    "print(len(train_imgs) + len(test_imgs))\n",
    "print(len(image_paths))\n",
    "print(len(train_imgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cal' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-0c247834f9e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcal\u001b[0m\u001b[0;31m#show raw image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_img_double\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_imgs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcropped_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mimgplot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'gray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cal' is not defined"
     ]
    }
   ],
   "source": [
    "#show raw image\n",
    "img = read_img_double(train_imgs[0][1], cropped_size)\n",
    "imgplot = matplotlib.pyplot.imshow(img, cmap = 'gray')\n",
    "print (img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show ground truth\n",
    "img = read_img_double(train_imgs[0][0], cropped_size)\n",
    "imgplot = matplotlib.pyplot.imshow(img, cmap = 'gray')\n",
    "print (img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the images are float32 matrixes as the keras backend is\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_up_layer(input_layer, kernel_size, downsample):\n",
    "    activation_function_pyramid = 'relu'\n",
    "    conv_layer = keras.layers.Conv2D(128, kernel_size, padding='same',\n",
    "                                     activation = activation_function_pyramid)(input_layer)\n",
    "    return keras.layers.MaxPooling2D(downsample, padding=\"valid\")(conv_layer)\n",
    "\n",
    "def create_down_layer(corresponding_layer_in_up_pyramid, previous_layer_down_pyramid, downsample = None):\n",
    "    if(previous_layer_down_pyramid is None):\n",
    "        prev_layer = corresponding_layer_in_up_pyramid\n",
    "    else:\n",
    "        prev_layer = keras.layers.Add()([corresponding_layer_in_up_pyramid, previous_layer_down_pyramid])\n",
    "    \n",
    "    return keras.layers.UpSampling2D(downsample)(prev_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_up_pyramid = keras.layers.Input(shape = (cropped_size[0], cropped_size[1], 1))\n",
    "print (base_up_pyramid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "downsample = [2, 2]\n",
    "kernel_size = [3, 3]\n",
    "\n",
    "up_layer1 = create_up_layer(base_up_pyramid, kernel_size, downsample)\n",
    "up_layer2 = create_up_layer(up_layer1, kernel_size, downsample)\n",
    "up_layer3 = create_up_layer(up_layer2, kernel_size, downsample)\n",
    "up_layer4 = create_up_layer(up_layer3, kernel_size, downsample)\n",
    "\n",
    "down_layer4 = create_down_layer(up_layer4, None, downsample)\n",
    "down_layer3 = create_down_layer(up_layer3, down_layer4, downsample)\n",
    "down_layer2 = create_down_layer(up_layer2, down_layer3, downsample)\n",
    "down_layer1 = create_down_layer(up_layer1, down_layer2, downsample)\n",
    "out_layer = keras.layers.Conv2D(1, kernel_size, padding=\"same\")(down_layer1)\n",
    "\n",
    "model = keras.models.Model(inputs = [base_up_pyramid], outputs = [out_layer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load images for training x -> input, y -> expected output\n",
    "import numpy\n",
    "def read_img_as_numpy_arr(path):\n",
    "    return keras.preprocessing.image.img_to_array(read_img_double(path, cropped_size))\n",
    "\n",
    "data = numpy.array([read_img_as_numpy_arr(img_path[1]) for img_path  in train_imgs])\n",
    "labels = numpy.array([read_img_as_numpy_arr(img_path[0]) for img_path  in train_imgs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.pyimagesearch.com/2017/12/11/image-classification-with-keras-and-deep-learning/\n",
    "model.fit(data, labels, epochs = 10, batch_size = 2, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
